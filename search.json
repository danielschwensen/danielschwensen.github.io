[{"title":"Managing Installed Applications with Homebrew on macOS","category":"","tags":"Homebrew macOS","url":"/2025-06-27-managing_applications_homebrew_on_macOS/","date":"2025-06-27","content":"Homebrew is a powerful package manager for macOS that allows users to install and manage software efficiently. In this article, we’ll explore how to list installed applications and remove unnecessary ones using Homebrew.\\n\\nListing Installed Packages\\n\\nTo see what software is installed via Homebrew, run:\\n```\\nbrew list\\n\\n```\\nThis command displays all installed formulae (command-line tools and libraries). If you also want to see GUI applications installed via Homebrew Cask, use:\\n```\\nbrew list --cask\\n\\n```\\nThis will show a list of applications installed using Cask, such as web browsers, terminal emulators, and text editors.\\n\\nUninstalling Unnecessary Applications\\n\\nTo remove an installed package, use:\\n```\\nbrew uninstall <package-name>\\n\\n```\\nFor example, to remove Visual Studio Code:\\n```\\nbrew uninstall --cask visual-studio-code\\n\\n```\\nIf you want to remove multiple packages at once:\\n```\\nbrew uninstall --cask iterm2 kap keka\\n\\n```\\nTo remove all installed Cask applications:\\n```\\nbrew list --cask | xargs brew uninstall --cask\\n\\n```\\n\\nCleaning Up\\n\\nAfter uninstalling applications, it’s a good idea to free up disk space with:\\n```\\nbrew cleanup\\n\\n```\\nThis removes outdated versions and unnecessary files.\\nBy following these steps, you can efficiently manage your macOS applications using Homebrew, ensuring your system stays clean and optimized.\\n"},{"title":"Resolving Windows Line Endings (CRLF) Issues in Shell Scripts","category":"","tags":"Linux grep","url":"/2025-05-25-Windows-Line-Endings/","date":"2025-05-25","content":"This note outlines three quick methods—using dos2unix, sed, or an editor conversion—to ensure the script runs without errors.\\n\\nWhen you run a shell script on a Unix-like system and see an error like:\n```\nzsh: ./script.sh: bad interpreter: /bin/bash^M: no such file or directory\n```\nthis indicates that your script was saved with Windows line endings (CRLF) instead of Unix line endings (LF). The extra ^M character causes the interpreter path to be misread.\\n\\nWhy It Happens\\n\\n- Windows vs. Unix: Windows uses CRLF (\\r\\n) for line breaks, while Unix-like systems use LF (\\n).\n- Impact on Scripts: The extra carriage return (\\r) is appended to the shebang line (e.g., /bin/bash^M), causing the system to fail in locating the correct interpreter.\\n\\nHow to Fix It\\n\\n1. Using dos2unix\\n\\nIf you have dos2unix installed, simply run:\n```\ndos2unix script.sh\n```\nThis command converts the file to Unix line endings.\\n\\n2. Using sed\\n\\nYou can also remove carriage returns using sed:\n```\nsed -i 's/\\r$//' script.sh\n```\nThis command edits the file in place, removing the \\r at the end of each line.\\n\\n3. Using a Text Editor\\n\\nOpen the script in an editor that supports different line endings (e.g., VS Code, Sublime Text, or Notepad++), and convert the file format to Unix (LF). Save the file afterwards.\\n\\n---\nBy ensuring your shell scripts use Unix line endings, you can avoid interpreter errors and ensure smooth execution across different environments."},{"title":"Extracting a Subdirectory with Git Subtree Split","category":"","tags":"Git","url":"/2025-04-06-Extracting_a_Subdirectory_with_Git_Subtree_Split/","date":"2025-04-06","content":"When you need to split a subdirectory from a larger repository while keeping its commit history, Git Subtree Split is a simple built-in solution.\\n\\n1. Update Your Local Repository\\n\\nBefore starting, ensure your repository is up-to-date. If you have any pending changes, commit them and pull the latest updates:\\n\\n```\ngit pull origin main\\n\\n```\n(Replace `main` with your branch name if needed.)\\n\\n2. Create a New Branch for the Subdirectory\\n\\nUse the subtree split command to extract your subdirectory (e.g., `WizzadPlus2022`) into a new branch:\\n\\n```\ngit subtree split --prefix=WizzadPlus2022 -b wizzadplus2022-only\\n\\n```\n- `--prefix=WizzadPlus2022`: Specifies the directory to extract.\n- `-b wizzadplus2022-only`: Creates a new branch containing only the commits affecting that directory.\\n\\n3. Set Up a New Repository\\n\\nCreate a new, empty repository on your favorite Git hosting service (GitHub, GitLab, etc.). Note the repository URL (e.g., git@github.com:`yourUsername/WizzadPlus2022.git`).\\n\\n4. Push the New Branch to the New Repository\\n\\nAdd the new remote and push your branch:\\n\\n```\ngit remote add wizzadplus2022 <NEW_REPO_URL>\ngit push wizzadplus2022 wizzadplus2022-only:main\\n\\n```\nThis command pushes your new branch as the `main` branch in the new repository."},{"title":"Install Homebrew on macOS Ventura","category":"","tags":"Homebrew macOS","url":"/2025-03-16-install_homebrew_on_macOS/","date":"2025-03-16","content":"Homebrew is a free and open-source package manager that simplifies the installation of software on macOS and Linux. It allows users to install, update, and manage software packages directly from the command line, making it easier to handle dependencies and maintain system cleanliness. \\n\\n# Installing Homebrew on macOS 13 Ventura\\n\\nTo install Homebrew on macOS 13 Ventura, follow these steps:\\nInstall Xcode Command Line Tools: Execute: \\n```\\nxcode-select --install\\n```\\nA prompt will appear; click ‘Install’ to proceed.\\n\\nInstall Homebrew: Run: \\n```\\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\\n```\\nThis script will download and install Homebrew.\\n\\nAdding Homebrew to Your PATH\\nTo ensure that Homebrew and its installed packages are accessible from the terminal, you need to add Homebrew to your shell’s PATH. This step is crucial for the proper functioning of Homebrew. Here’s how to do it: \\n\t1.\tDetermine Your Shell:\\n```\\necho $SHELL\\n```\\n\\nIf the output includes /bin/zsh, you’re using zsh. If it shows /bin/bash, you’re using bash.\\n\\nAdd Homebrew to the PATH:\\nFor zsh Users:\\nOpen (or create) your .zprofile file:\\n```\\nnano ~/.zprofile\\n```\\n\\nAdd the following line to the file:\\n```\\neval \"$(/opt/homebrew/bin/brew shellenv)\"\\n```\\n\\nFor bash Users:\\nOpen (or create) your .bash_profile file:\\n```\\nnano ~/.bash_profile\\n```\\n\\nAdd the following line to the file:\\n```\\neval \"$(/opt/homebrew/bin/brew shellenv)\"\\n```\\n\\nApply the Changes:\\nTo immediately apply the changes without restarting the terminal, run:\\n```\\nsource ~/.zprofile\\n```\\nor\\n```\\nsource ~/.bash_profile\\n```\\ndepending on your shell.\\n\\nBy following these steps, Homebrew will be added to your PATH, ensuring that you can use the brew command and access the software installed via Homebrew seamlessly.\\n\\n# Verify Installation\\n\\nAfter installation, confirm that Homebrew is set up correctly by running:\\n```\\nbrew doctor\\n```\\nIf everything is properly installed, you’ll see the message “Your system is ready to brew.”\\n\\n# Uninstalling Homebrew\\n\\nIf you need to uninstall Homebrew, execute the following command in Terminal:\\n```\\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/uninstall.sh)\"\\n```\\nThis command will remove Homebrew and all installed packages from your system.\\n"},{"title":"Quick Linux Desktop Shutdown and Custom Alias Setup","category":"","tags":"Linux","url":"/2025-02-23-Quick-Linux-Desktop-Shutdown-and-Custom-Alias-Setup/","date":"2025-02-23","content":"Quick reference for shutting down Linux systems via terminal - both standard commands and how to create a custom shortcut (alias 'sd') for faster access. Added this because I always forget the exact shutdown commands and the alias setup steps.\\n\\nThe quickest ways to shut down your Linux system via terminal:\n- shutdown now - safest method, properly saves data\n- poweroff - short command, similar to shutdown now\n- init 0 - classic Unix command, works on all systems\n- halt - stops all processes and system\\n\\nCreate Custom Alias\\n\\nTo set up a convenient shutdown alias:\n1. Open .bashrc:\n```\nnano ~/.bashrc\n```\n2. Add at the end:\n```\nalias sd='shutdown now'\n```\n3. Save file: CTRL + O, ENTER, CTRL + X\n4. Reload .bashrc:\n```\nsource ~/.bashrc\n```\nNow you can simply type sd to shutdown your system.\nPro tip: Consider using alias sd='sudo shutdown now' if you always need root privileges."},{"title":"Managing Packages with Chocolatey on Windows","category":"","tags":"Windows Chocolatey","url":"/2025-01-04-Managing-Packages-with-Chocolatey-on-Windows/","date":"2025-01-04","content":"Chocolatey is a powerful package manager for Windows that simplifies software installation and management. \\n\\nPrerequisites\\n\\n- Run PowerShell or Command Prompt as Administrator\\n- Installation directory: `C:\\ProgramData\\chocolatey`\\n\\nEssential Commands\\n\\n\\nInstallation & Updates\\n\\n\\n```\\n# Install a package\\nchoco install <package-name>\\n\\n# Update a specific package\\nchoco upgrade <package-name>\\n\\n# Update all packages\\nchoco upgrade all -y\\n```\\n\\nPackage Management\\n\\n```\\n# List installed packages\\nchoco list\\n\\n# Check for outdated packages\\nchoco outdated\\n\\n# Search for packages\\nchoco search <package-name>\\n\\n# Get package information\\nchoco info <package-name>\\n\\n# Uninstall a package\\nchoco uninstall <package-name>\\n```\\n\\nExample: Managing Terraform\\n\\n```\\n# Install Terraform\\nchoco install terraform\\n\\n# Check Terraform version\\nterraform --version\\n\\n# or\\nchoco list terraform\\n\\n# Update Terraform\\nchoco upgrade terraform\\n```\\n\\nTips\\n\\n1. Use `-y` flag to automatically confirm actions\\n2. Pin important packages to prevent automatic updates: \\n3. Keep Chocolatey updated: \\n4. Restart terminal after installing new packages\\n5. Use `--what-if` to preview changes before execution\\n\\n\\nUnderstanding Shims\\n\\nChocolatey uses shims to make command-line programs accessible globally. A shim is a small file that redirects to the actual executable of an installed program. They are automatically created in `C:\\ProgramData\\chocolatey\\bin`.\\nBenefits of shims:\\n- Makes commands available immediately in any terminal\\n- Allows running programs without knowing their exact installation path\\n- Enables seamless updates without changing PATH variables\\nExample: When you install Terraform via Chocolatey, it creates a shim that allows you to run terraform from any location, while the actual executable might be in C:\\ProgramData\\chocolatey\\lib\\terraform\\tools\\."},{"title":"Ubuntu Firewall Setup and Security Checks","category":"","tags":"Linux Ubuntu firewall security","url":"/2024-12-01-Ubuntu-Firewall-Setup-and-Security-Checks/","date":"2024-12-01","content":"Basic commands and steps for securing Ubuntu using UFW firewall, setting up automated security updates, and implementing daily security checks with log rotation. \\n\\n# 1. Check Firewall Status\\n\\n```\\nsudo ufw status\\n\\nsudo ufw status verbose\\n\\nsudo ufw status numbered\\n```\\n\\n# 2. Install and Enable UFW\\n\\n\\n```\\n# Check if installed\\ndpkg -l | grep ufw\\n# or\\n\\nwhich ufw\\n\\n# Install if needed\\nsudo apt update\\nsudo apt install ufw\\n\\n# Enable firewall\\nsudo ufw enable\\n```\\n\\n# 3. Basic UFW Configuration\\n\\n```\\n# Default policies\\nsudo ufw default deny incoming\\nsudo ufw default allow outgoing\\n\\n# Common services\\nsudo ufw allow ssh # Port 22\\nsudo ufw allow 80/tcp # HTTP\\nsudo ufw allow 443/tcp # HTTPS\\n```\\n\\n# 4. System Security Check Commands\\n\\n```\\n# Check open ports\\nsudo ss -tulpn\\n\\n# Check login attempts\\nsudo last\\nsudo grep \"Failed password\" /var/log/auth.log\\n\\n# Check sudo usage\\nsudo grep \"sudo\" /var/log/auth.log\\n```\\n\\n# 5. Enable Automatic Security Updates\\n\\n```\\nsudo apt install unattended-upgrades\\nsudo dpkg-reconfigure --priority=low unattended-upgrades\\n```\\n\\n# 6. Daily Security Check Script\\n\\n\\nCreate a script in `/etc/cron.daily/security-check` that:\\n- Monitors failed login attempts\\n- Checks network connections\\n- Tracks system resources\\n- Rotates logs (keeps last 10 backups)\\n- Creates daily reports in `/var/log/security-check.log`\\n\\n# Notes:\\n\\n\\n- Default Ubuntu installation doesn't enable UFW by default\\n- Basic system is secure even without UFW if no services are installed\\n- Monitor auth.log for suspicious activities\\n- GUI configuration available through GUFW: `sudo apt install gufw`\\n![GUFW]( )\\n- Regularly check system logs\\n- Keep system updated: `sudo apt update && sudo apt upgrade`\\n- Monitor open ports and running services"},{"title":"Understanding Linux Shells and Configuration","category":"","tags":"Linux shell bash","url":"/2024-11-17-Understanding-Linux-Shells-and-Configuration/","date":"2024-11-17","content":"How to check which shell I'm using and where the important config files are located. \\n\\n# Which shell am I using?\\n\\nCheck your current shell using any of these commands:\\n\\n```\necho $SHELL # Shows path to default shell\\n\\necho $0 # Shows shell name\\n\\ncat /etc/shells # Lists all available shells\n```\\n\\n# Changing your shell\\n\\nChange your default shell using:\\n\\n```\nchsh -s /bin/zsh # Change to ZSH\\n\\nchsh -s /bin/bash # Change to Bash\n```\nChanges take effect after next login.\\n\\nShell Configuration Files\\n\\nKey configuration files and their purposes:\n1. ~/.bashrc - For interactive non-login shells - Contains: aliases, functions, prompt settings - Used in most terminal windows you open\n2. ~/.profile - For login shells - Contains: environment variables, PATH settings - Read by multiple shells, not just bash\n3. /etc/passwd - Stores default shell for each user - Format: `username:x:uid:gid:comment:home:shell` - Don't edit directly; use `chsh` instead\\n\\n# Loading Order\\n\\nLogin Shell:\n1. /etc/profile\n2. First found of: ~/.profile, ~/.bash_login, or ~/.bash_profile\n3. On exit: ~/.bash_logout\\n\\nNon-Login Shell (regular terminal):\n1. /etc/bash.bashrc\n2. ~/.bashrc\\n\\nOn Ubuntu, ~/.bashrc is the main configuration file you'll work with for most shell customizations."},{"title":"How to Change the Creation Timestamp of JPG Files with PowerShell?","category":"","tags":"Powershell","url":"/2024-09-12-How-to-Change-the-Creation-Timestampwith-Powershell/","date":"2024-09-12","content":"Do you need to change the creation timestamps of JPG files? PowerShell offers a quick and efficient way to do this.\\n\\n```\n$targetPath = \"F:\\Downloads\\Target\"\\n\\n$newCreationTime = \"2001-09-11 00:00:00\"\\n\\nGet-ChildItem -Path $targetPath -Filter *.jpg | ForEach-Object { $_.CreationTime = $newCreationTime Write-Host \"CreationTime for file $($_.Name) was changed to $newCreationTime\"\n}\n```\\n\\nYou can also change other timestamps like LastWriteTime or LastAccessTime by using the corresponding property:\\n\\n```\n$_.LastWriteTime = $newCreationTime\n```"},{"title":"How to connect to a Docker mysql container?","category":"","tags":"Docker","url":"/2024-08-28-How_to_connect_to_a_Docker_mysql_container/","date":"2024-08-28","content":"Verifying your MySQL Docker container connection.\\n\\nFirst, make sure your MySQL container is actually running:\\n\\n```\\ndocker ps | grep mysql\\n```\\n\\nVerify the port mapping:\\n```\\ndocker port <container_id_or_name>\\n```\\n\\nThis should show you something like 3306/tcp -> 0.0.0.0:3306\\n\\nTry connecting with the IP address 127.0.0.1:\\n\\n```\\nmysql -h 127.0.0.1 -P <mapped_port> -u root -p\\n```\\n\\nIf you're still having trouble, you can always connect to MySQL from within the container itself:\\n```\\ndocker exec -it <container_id_or_name> mysql -u root -p\\n```\\n\\nIf the connection is successful, you'll see the MySQL prompt, which typically looks like this:\\n```\\nmysql>\\n```\\n\\nThis indicates that the MySQL server is up and running, and you've successfully connected as the root user.\\n\\nTo further verify the connection and server status, you can run a few simple commands:\\n\\n1. Check the server version:\\n```\\nSELECT VERSION();\\n```\\n\\n2. Show the current date and time on the server:\\n```\\nSELECT NOW();\\n```\\n\\n3. List all databases:\\n```\\nSHOW DATABASES;\\n```\\n\\nIf these commands execute without errors, it confirms that the MySQL server is functioning correctly.\\nTo exit the MySQL prompt, type:\\n```\\nEXIT;\\n```"},{"title":"How to Install Git on Windows","category":"","tags":"Git","url":"/2023-12-03-Install_Git_Windows/","date":"2023-12-03","content":"Download Git: Visit the official Git website at git-scm.com to download the latest version for Windows.\\n\\n# Installation Process\\n\\n![Git Bash 1]( )\\n\\n![Git Bash 2]( )\\n\\n![Git Bash 3]( )\\n\\n![Git Bash 4]( )\\n\\n![Git Bash 5]( )\\n\\n![Git Bash 6]( )\\n\\n![Git Bash 7]( )\\n\\n![Git Bash 8]( )\\n\\n![Git Bash 9]( )\\n\\n![Git Bash 10]( )\\n\\n# Post-Installation Steps\\n\\nVerifying the Installation\\n\\n- Open your command prompt or Git Bash terminal.\n- Type git --version and press Enter. If Git is installed correctly, it should display the installed version.\\n\\n# Configuring Git\\n\\n- To personalize your Git environment, configure your user name and email using the following commands:\n```\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your.email@example.com\"\n```\\n\\n- These details will be used in your commits."},{"title":"How to check on Linux if Docker is running","category":"","tags":"Linux Docker","url":"/2023-09-27-How-to-check-if-Docker-is-running/","date":"2023-09-27","content":"Docker is a popular tool for developing and running applications in containers. It can be used on a variety of platforms, including Linux.\\n\\nThere are a few ways to check if Docker is running on Linux.\\n\\n1. Use the systemctl command.\\n\\n```\\nsudo systemctl status docker\\n```\\n\\nIf the Docker daemon is running, you will see an output similar to this:\\n\\n\\n\\n```\\n● docker.service - Docker Application Container Engine\\n Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)\\n Active: active (running) since Wed 2023-08-03 14:27:03 UTC; 3h 3min ago\\n Main PID: 1326 (dockerd)\\n Tasks: 27\\n Memory: 15.4M\\n CPU: 8ms\\n CGroup: /system.slice/docker.service\\n └─1326 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock\\n```\\n\\n\\n\\n2. Use the docker info command.\\n\\n```\\ndocker info\\n```\\n\\nIf the Docker daemon is running, you will see an output similar to this:\\n\\n\\n```\\nClient:\\n Version: 20.10.8\\n ...\\n\\nServer:\\n Version: 20.10.8\\n ...\\n```\\n\\n\\n3. Check the process ID of the Docker daemon.\\n\\n\tThe Docker daemon writes its process ID to the file /var/run/docker.pid. You can check if the Docker daemon is running by checking if this file exists and if the process ID associated with it is running.\\n\\n```\\nsudo cat /var/run/docker.pid\\n```\\n\\nIf the Docker daemon is running, you will see a number. If the number is not running, the Docker daemon is not running."},{"title":"Using PowerShell PSReadLine","category":"","tags":"Powershell","url":"/2023-08-04-PowerShell-PSReadLine/","date":"2023-08-04","content":"**PSReadLine**, a module that offers improved command-line editing and rich history capabilities.\\n\\n### **Installation**\\n\\nBefore using PSReadLine, you need to have it installed. It often comes pre-installed with Windows 10 and PowerShell Core, but if you need to install it manually:\\n\\n```powershell\nInstall-Module -Name PSReadLine -Force -SkipPublisherCheck\n```\\n\\n### **Basic Features**\\n\\n**Syntax Highlighting:** \\n\\nOut of the box, PSReadLine offers real-time syntax highlighting, making it easier to spot mistakes as you type.\\n\\n**Keyboard Shortcuts:** \\n\\nPSReadLine comes packed with a variety of shortcuts, similar to those in `bash`, that can make navigation and command editing a breeze.\\n\\n- **Ctrl + Arrow Keys:** Navigate through tokens (words).\n- **Ctrl + A:** Move to the start of the line.\n- **Ctrl + E:** Move to the end of the line.\\n\\n### **Command History**\\n\\nOne of PSReadLine's most robust features is its enhanced history management.\\n\\n**Persistent History:** \\n\\nCommands are saved across sessions, so you can recall commands you used days or even weeks ago.\\n\\n**Search History:** \\n\\nEasily search through your command history by pressing **Ctrl + R**. Start typing, and PSReadLine will show matches from your history.\\n\\n![PSReadLine]( )\\n\\n### **Customization**\\n\\nPSReadLine is highly customizable. To edit the settings:\\n\\n```powershell\nnotepad.exe $PROFILE\n```\\n\\nThis will open your PowerShell profile in Notepad, where you can customize PSReadLine to your liking. \\n\\n**Prediction Based on History:** You can set PSReadLine to predict the next command based on your history using:\\n\\n```powershell\nSet-PSReadLineOption -PredictionSource History\n```\\n\\n**View Style for Predictions:** You can customize the view of the predictions. For a list view style, use:\\n\\n```powershell\nSet-PSReadLineOption -PredictionViewStyle ListView\n```\\n\\n### **MindMap**\\n\\n![PSReadLineMindMap]( )\\n\\n### **Conclusion**\\n\\n**PSReadLine** is a must-have module for anyone regularly working with PowerShell. Its enhanced editing, history capabilities, and customization options can greatly improve your productivity."},{"title":"How to list the content of a Glacier vault?","category":"","tags":"AWS Glacier CLI","url":"/2023-07-03-How-to-list-the-content-of-a-Glacier-vault/","date":"2023-07-03","content":"Want a quick look at what's inside your AWS Glacier vault? Retrieving an inventory is easier than you might think. This post walks you through the simple steps to initiate an inventory-retrieval job and download your vault's contents.\\n\\nFirst you need to initiate a job to retrieve an inventory of a vault.\\n\\nHere is the general process:\\n\\n1. Initiate an inventory-retrieval job: You can do this via the AWS Management Console, AWS CLI, or AWS SDKs. The job essentially requests AWS Glacier to compile an inventory of the content of your vault. This job typically takes several hours to complete because Glacier is optimized for infrequent access.\n2. After the job is complete, download the output of the job: The output is a file that contains the inventory of your vault. The inventory includes information about each archive in the vault, such as the archive ID, description, and creation date.\nHere's an example of how to initiate an inventory-retrieval job using the AWS CLI:\\n\\n```\naws glacier initiate-job --account-id - --vault-name your_vault_name --job-parameters '{\"Type\": \"inventory-retrieval\"}'\\n\\n```\\n\\nReplace your_vault_name with the name of your vault.\nThis command will return a job ID, which you can use to check the status of the job. You can do that with this command:\\n\\n```\naws glacier describe-job --account-id - --vault-name your_vault_name --job-id your_job_id\\n\\n```\\n\\nReplace your_vault_name with the name of your vault, and your_job_id with the job ID returned by the initiate-job command.\\n\\nOnce the job is complete, you can download the output of the job with this command:\\n\\n```\naws glacier get-job-output --account-id - --vault-name your_vault_name --job-id your_job_id output_file_name\\n\\n```\\n\\nReplace your_vault_name with the name of your vault, your_job_id with the job ID, and output_file_name with the name you want to give to the output file."},{"title":"How to Upload files and folder to AWS s3 with a CLI","category":"","tags":"AWS S3 CLI","url":"/2023-06-28-How-to-Upload-files-and-folder-to-AWS-s3-with-a-CLI/","date":"2023-06-28","content":"To upload files and folders to Amazon S3 using the AWS Command Line Interface (CLI), you can use the aws s3 cp command.\\n\\nHere is the basic syntax for the aws s3 cp command:\\n\\n```\naws s3 cp <local-path> <s3-path>\\n\\n```\\n\\n- local-path is the path to the file or folder on your local machine that you want to upload.\n- s3-path is the path to the S3 bucket where you want to upload the file or folder. It should be in the format s3://<bucket-name>/<key>, where <bucket-name> is the name of the S3 bucket and <key> is the path to the location within the bucket where you want to upload the file or folder.\\n\\nFor example, to upload a file named file.txt from your local machine to the root of an S3 bucket named my-bucket, you could use the following command:\\n\\n```\naws s3 cp file.txt s3://my-bucket/file.txt\\n\\n```\\n\\nTo upload a folder named my-folder from your local machine to the root of an S3 bucket, you can use the --recursive flag to copy all the files and subfolders within the folder:\\n\\n```\naws s3 cp my-folder s3://my-bucket/ --recursive\\n\\n```\\n\\nYou can also specify a different destination folder within the S3 bucket by adding it to the s3-path. For example, to upload the contents of my-folder to a folder named s3-folder within the S3 bucket, you can use the following command:\\n\\n```\naws s3 cp my-folder s3://my-bucket/s3-folder/ --recursive\\n\\n```\\n\\nNote that the aws s3 cp command will overwrite any existing files with the same name in the destination. To avoid overwriting existing files, you can use the --dryrun flag to test the command without actually uploading the files.\\n\\nYou can also use the aws s3 sync command to synchronize a local folder with an S3 bucket or a folder within an S3 bucket.\\n\\nHere is the basic syntax for the aws s3 sync command:\\n\\n```\naws s3 sync <local-path> <s3-path>\\n\\n```\\n\\n- local-path is the path to the folder on your local machine that you want to sync with the S3 bucket.\n- s3-path is the path to the S3 bucket or folder where you want to sync the local folder. It should be in the format s3://<bucket-name>/<key>, where <bucket-name> is the name of the S3 bucket and <key> is the path to the location within the bucket where you want to sync the local folder.\\n\\nFor example, to sync the contents of a local folder named my-folder with the root of an S3 bucket named my-bucket, you could use the following command:\\n\\n```\naws s3 sync my-folder s3://my-bucket/\\n\\n```\\n\\nTo sync the contents of my-folder with a folder named s3-folder within the S3 bucket, you can use the following command:\\n\\n```\naws s3 sync my-folder s3://my-bucket/s3-folder/\\n\\n```\\n\\nThe aws s3 sync command will copy new and updated files from the local folder to the S3 bucket, and it will also delete any files from the S3 bucket that are not present in the local folder.\nYou can use the --delete flag to disable this behavior."},{"title":"How to Create and Manage Python Virtual Environments","category":"","tags":"Python","url":"/2023-05-08-How-to-Create-and-Manage-Python-Virtual-Environments/","date":"2023-05-08","content":"Python is a powerful and versatile programming language, widely used for web development, data analysis, artificial intelligence, and more. As a developer, you might find yourself working on multiple projects with different sets of dependencies and configurations. This is where Python virtual environments come to the rescue! In this blog post, we'll explore the benefits of using virtual environments, how to create and manage them, and best practices to keep your projects organized and conflict-free.\\n\\n# Why use Python virtual environments?\\n\\nPython virtual environments are self-contained, isolated environments that allow you to work on different projects without causing conflicts between their respective dependencies, versions, and settings. Some key benefits of using virtual environments include:\\n\\n1. Project isolation: Maintain separate environments for each project, preventing conflicts and ensuring stability.\n2. Dependency management: Install and manage packages specific to each project without affecting the system-wide Python installation.\n3. Reproducible builds: Easily share your project with others by providing a list of dependencies and their versions, ensuring a consistent development environment.\\n\\n# Creating a Python virtual environment:\\n\\nTo create a Python virtual environment, you can use built-in tools like venv (available from Python 3.3 onwards) or third-party packages like virtualenv. In this guide, we'll focus on using venv.\\n\\nFollow these steps to create a new virtual environment:\\n\\n1. Open a terminal (Linux or macOS) or command prompt (Windows).\n2. Navigate to the directory where you want to create the virtual environment.\n3. Run the following command, replacing myenv with your desired environment name:\n``` python -m venv .venv\n```\n4. Activate the virtual environment:\n- On Windows, run:\n``` myenv\\Scripts\\activate\n```\n- On Linux or macOS, run:\n```\nsource myenv/bin/activate\n```\nAfter activation, your terminal or command prompt will display the virtual environment's name in parentheses (e.g., (myenv)). Now, any package you install or changes you make to Python settings will only affect the virtual environment.\\n\\n# Managing packages in a virtual environment:\\n\\nUpdate your virtual environment's package manager (pip) to the latest version by running:\\n\\n```\npython -m pip install --upgrade pip\n```\\n\\nInstall a specific version of a package, run:\\n\\n```\npip install package_name==version_number\n```\\n\\nOr use a requirements file to install multiple packages at once:\\n\\n```\npip install -r requirements.txt\n```\\n\\nTo generate a list of installed packages and their versions, run:\\n\\n```\npip freeze > requirements.txt\n```\\n\\nTo generate a list of installed packages without their versions, run:\\n\\n```\npip freeze --local | % { $_ -replace '==.*','' } | Set-Content requirements.txt\n```\\n\\n# Deactivating the virtual environment:\\n\\nWhen you're done working on a project, deactivate the virtual environment to return to the system-wide Python installation by running:\\n\\n```\ndeactivate\\n\\n```"},{"title":"Securely Storing and Using Credentials in PowerShell Scripts","category":"","tags":"Powershell","url":"/2023-03-23-Securely_Storing_and_Using_Credentials_in_PowerShell_Scripts/","date":"2023-03-23","content":"When working with PowerShell scripts, it's often necessary to use sensitive information like usernames and passwords to authenticate against various services or systems. However, storing these credentials in plain text is a security risk that should be avoided. In this blog post, we'll discuss how to securely store and use credentials in PowerShell without exposing them in plain text.\\n\\nStep 1: Encrypt and Store the Password\\n\\nThe first step is to securely store your password by encrypting it and saving it to a file. PowerShell provides a ConvertFrom-SecureString cmdlet that can be used to save encrypted strings to a file. \\n\\nHere's how to do it:\\n\\n```\n# Type the password in the console when prompted\n$Credential = Get-Credential -UserName 'YourUserName' -Message 'Enter your password'\\n\\n# Save the encrypted password to a file\n$Credential.Password | ConvertFrom-SecureString | Set-Content 'C:\\path\\to\\secure_password.txt'\n```\\n\\nThis code snippet prompts you to enter your password in a secure manner and then saves the encrypted password to a file. Keep in mind that this encrypted password can only be decrypted by the same user and on the same computer where it was encrypted.\\n\\nStep 2: Use the Encrypted Password in Your Script\\n\\nOnce the password is securely stored, you can use it in your PowerShell scripts by reading the encrypted password from the file and creating a PSCredential object.\\n\\nHere's an example:\\n\\n```\n# Read the encrypted password from the file\n$SecurePassword = Get-Content 'C:\\path\\to\\secure_password.txt' | ConvertTo-SecureString\\n\\n# Create a PSCredential object using the encrypted password\n$UserName = 'YourUserName'\n$Credential = New-Object System.Management.Automation.PSCredential($UserName, $SecurePassword)\\n\\n# Use the credential object in your script, e.g., for a remote session\n$Session = New-PSSession -ComputerName 'RemoteComputerName' -Credential $Credential\nInvoke-Command -Session $Session -ScriptBlock { # Your commands here }\n```\\n\\nIn this code snippet, we read the encrypted password from the file, create a PSCredential object, and then use that object for authentication. This ensures that the password is not exposed in plain text within the script.\\n\\nConclusion\\n\\nBy encrypting and securely storing sensitive information like passwords, you can minimize the risk of unauthorized access to your scripts and systems. Using the PSCredential object and related cmdlets in PowerShell makes it easy to manage and use credentials without exposing them in plain text."},{"title":"grep","category":"","tags":"Linux grep","url":"/2023-02-26-grep/","date":"2023-02-26","content":"The grep command in Linux is a powerful tool for searching and filtering text. It stands for \"global regular expression print,\" and it allows you to search for patterns within text files and output the matching lines.\\n\\nBasic syntax\\n\\nThe basic syntax for using grep is as follows:\\n\\n```\ngrep [options] pattern [files]\\n\\n```\nHere is a breakdown of the components:\\n\\n- options: optional flags that control the behavior of grep\n- pattern: the regular expression pattern to search for\n- files: a list of one or more files to search; if not specified, grep will search through the standard input\\n\\nRegular expressions\\n\\nA regular expression is a sequence of characters that defines a search pattern. Regular expressions can include special characters and metacharacters that allow you to match patterns more flexibly. Some common metacharacters include:\n- .: matches any single character\n- *: matches zero or more of the preceding character or expression\n- `[]`: matches any single character within the brackets\n- ^: negates the character set if it appears as the first character within the brackets\n- `[:alnum:]`: matches any alphanumeric character\n- `[:alpha:]`: matches any alphabetic character\n- `[:digit:]`: matches any digit\n- `[:lower:]`: matches any lowercase character\n- `[:upper:]`: matches any uppercase character\\n\\nHere are some examples of regular expressions:\\n\\n- abc: matches the string \"abc\"\n- a.c: matches any string that begins with \"a\" and ends with \"c\" with any character in between\n- a*c: matches any string that begins with \"a\" and ends with \"c\" with zero or more \"a\" characters in between\n- `[abc]`: matches any string that contains \"a\", \"b\", or \"c\"\n- `[^abc]`: matches any string that does not contain \"a\", \"b\", or \"c\"\\n\\nOptions\\n\\ngrep has many options that allow you to control its behavior. Here are some common ones:\\n\\n- -i: ignores case\n- -v: inverts the match, showing lines that do not match the pattern\n- -c: counts the number of matches\n- -n: shows the line numbers of the matches\n- -E: treats the pattern as an extended regular expression\n- -w: matches the pattern as a whole word\n- -o: shows only the matched part of the line\\n\\nExamples\\n\\nHere are some examples of using grep:\\n\\n- grep \"hello\" file.txt: searches for the string \"hello\" in the file \"file.txt\"\n- grep -i \"hello\" file.txt: searches for the string \"hello\" (ignoring case) in the file \"file.txt\"\n- grep -v \"hello\" file.txt: searches for lines that do not contain the string \"hello\" in the file \"file.txt\"\n- grep -c \"hello\" file.txt: counts the number of lines that contain the string \"hello\" in the file \"file."},{"title":"Parse command line tool output with Powershell","category":"","tags":"Powershell","url":"/2023-01-29-Parse-command-line-tool-output-with-Powershell/","date":"2023-01-29","content":"The other day, I had to restart a Windows server using only Powershell. The catch was that I had to do it only if the output of a command line tool was a certain way. I also kept a log for documentation purposes.\\n\\nThis script shows how easy it was.\\n\\n```\n$oascmd = \"C:\\path\\to\\oascmd.exe\"\n$output = & $oascmd\\n\\n# Check if the output contains the string \"alive\"\nif($output -match \"alive\") { Restart-Service -Name \"Station_xl\" -ErrorAction SilentlyContinue\\n\\n $time = Get-Date -Format \"MM/dd/yyyy HH:mm:ss\" $log = \"$time - Service Station_xl stopped and started. Output: $output\" Add-Content -Path \"C:\\path\\to\\logfile.txt\" -Value $log\n}\n```\\n\\nWith this script, you can check the status of a service and restart it automatically if needed. This saves you time and effort."},{"title":"Stack vs Heap in C#","category":"","tags":"C# .NET","url":"/2022-12-20-C_Sharp-stack-vs-heap/","date":"2022-12-20","content":"In C#, there are two main ways to store data in memory: on the stack and on the heap. \\n\\n## The Stack\\n\\nThe stack is a memory region used to store local variables and function call data. It is a LIFO (last-in, first-out) structure, meaning that the last item placed on the stack is the first one to be removed. When a function is called, its local variables and any other data it needs are pushed onto the stack. When the function returns, this data is popped off the stack.\\n\\nOne of the main advantages of the stack is that it is very fast to allocate and deallocate memory, as data is simply pushed and popped off the top of the stack. This makes the stack a good choice for storing temporary data that is used and discarded quickly.\\n\\nHowever, the stack has a fixed size, and if a program tries to push more data onto the stack than it has room for, it will result in a stack overflow. This can cause the program to crash or behave unexpectedly.\\n\\n## The Heap\\n\\nThe heap is a memory region used to store dynamically-allocated objects. It is much larger than the stack and has no fixed size, so it can grow or shrink as needed. When an object is created on the heap, it is given a memory address that can be used to access it.\\n\\nOne of the main advantages of the heap is that it allows objects to have a longer lifetime than objects stored on the stack. When an object is stored on the stack, it is automatically deallocated when the function that created it returns. However, an object on the heap can exist for as long as it is needed, as it is not tied to any particular function call.\\n\\nThe heap is also useful for storing objects that need to be shared among multiple functions or threads. However, allocating and deallocating memory on the heap is generally slower than on the stack, as it requires more complex operations.\\n\\n## Choosing Between the Stack and the Heap\\n\\nIn general, it is best to store temporary data on the stack and long-lived objects on the heap. This can help to improve the performance of your program, as the stack is faster and the heap is more flexible.\\n\\nHowever, there are some situations where it is necessary to use the heap even for temporary data. For example, if you need to store a large array or a struct with many fields, it may not fit on the stack. In these cases, it is necessary to allocate the data on the heap.\\n\\nIt is also possible to manually control the location of an object in memory using the fixed keyword in C#. This allows you to specify that an object should be stored on the stack or the heap, regardless of its default behavior. However, this should generally be avoided unless absolutely necessary, as it can be difficult to use correctly and can have unintended consequences.\\n\\nIn summary, understanding the difference between the stack and the heap is important for any C# programmer. The stack is faster but has a fixed size, while the heap is more flexible but slower. Choosing the right location to store your data can have significant impacts on the performance and behavior of your program."},{"title":"mklink /D","category":"","tags":"Windows cli","url":"/2022-12-17-mklink/","date":"2022-12-17","content":"The <code>mklink</code> command is a powerful tool in the Windows command line that allows you to create symbolic links. A symbolic link is a special type of file that points to another file or directory on your system. When you access the symbolic link, it behaves as if you are accessing the target file or directory, even though the two are technically separate.\\n\\nThere are two types of symbolic links: file symbolic links and directory symbolic links. \\n\\nFile symbolic links point to a specific file, while directory symbolic links point to a directory. You can use the <code>mklink</code> command with the <code>/D</code> flag to create a directory symbolic link.\nTo use the <code>mklink</code> command with the <code>/D</code> flag, open a command prompt window and type the following:\\n\\n```\nmklink /D <link> <target>\n```\\n\\nReplace **\\<link>** with the path and name of the symbolic link you want to create, and **\\<target>** with the path of the target directory. For example, to create a symbolic link at <code>C:\\link_to_documents</code> that points to the <code>D:\\documents</code> directory, you would use the following command:\\n\\n```\nmklink /D C:\\link_to_documents D:\\documents\n```\\n\\nWhen you access the <code>C:\\link_to_documents</code> directory, it will behave as if you are accessing the <code>D:\\documents</code> directory, even though the two are technically separate.\\n\\nIt's important to note that creating symbolic links requires administrator privileges. You may need to run the <code>mklink</code> command from an elevated command prompt to create the symbolic link.\nThere are many uses for symbolic links, such as creating a shortcut to a frequently accessed directory or consolidating multiple directories into one location. The <code>mklink</code> command with the <code>/D</code> flag is a handy tool to have in your toolkit when working with directories in Windows."},{"title":"My favorite Windows 10 keyboard shortcuts","category":"","tags":"Windows","url":"/2022-07-31-My-favorite-Windows-keyboard-shortcuts/","date":"2022-07-31","content":"In today's fast-paced digital era, saving a few seconds here and there can accumulate to significant time savings over the long run. One way to achieve this is by mastering keyboard shortcuts. Whether you're an avid Windows 10 user looking to boost your productivity or someone new wanting a crash course on the most effective shortcuts, this post is for you. Dive into my handpicked list of favorite Windows 10 shortcuts, from simplifying your file management in the Windows File Explorer to browsing the web more efficiently. Let's streamline your tasks and make every keystroke count!\\n\\n## Windows File Explorer\\n\\nOpen Windows Explorer\\n- WIN + E\\n\\nNew folder\\n- Ctrl + Shift + N\\n\\nChange file explorer view\\n- Ctrl + Shift + 1-6\\n\\nView properties of a file\\n- Alt + 1 (use Ctrl + Tab to browse through the tabs)\\n\\n## Productivity\\n\\nHide all windows except the active one\\n- WIN + Home (Pos1)\\n\\nAuto-size the columns in Details View in a File Explorer window. Works in most places where the ListView Common Control is used.\\n- Ctrl + Shift + NUM PAD PLUS\\n\\nScreenshot (screen selection)\\n- WIN + Shift + S\\n\\nShow Desktop\\n- WIN +D\\n\\nEMOJIs\\n- WIN + .\\n\\nSize a window to half my screen\\n- WIN + Arrow Keys\\n\\nTask Manager\\n- Ctrl + Shift + ESC\\n\\nSwitch between open programs\\n- ALT + TAB\\n\\n## Browser\\n\\nDelete Cache\\n- Ctrl + Shit + Del\\n\\nClose Window\\n- Ctrl + W\\n\\nChange tabs\\n- Ctrl + Page Up and Ctrl + Page Down"},{"title":"AWS - How to search for IP addresses - CLI","category":"","tags":"AWS CLI network","url":"/2022-06-30-AWS-How-to-search-for-IP-addresses-CLI/","date":"2022-06-30","content":"How to find out which resource owns this IP in AWS.\\n\\nPrivate IP\n```\naws ec2 describe-network-interfaces --filters Name=addresses.private-ip-address,Values=10.0.0.0 --region eu-west-1\n```\\n\\nPublic IP\n```\naws ec2 describe-network-interfaces --filters Name=addresses.association.public-ip,Values=1.1.1.1 --region eu-west-1\n```\\n\\nSource:\nhttps://docs.aws.amazon.com/cli/latest/reference/ec2/describe-network-interfaces.html\\n\\nhttps://aws.amazon.com/de/premiumsupport/knowledge-center/vpc-find-owner-unknown-ip-addresses/"},{"title":"Windows Package Manager WinGet in a Nutshell","category":"","tags":"Windows winget","url":"/2022-05-29-Windows_Package_Manager_WinGet_in_a_Nutshell/","date":"2022-05-29","content":"The Windows Package Manager (also known as winget) is a free and open-source package manager designed by Microsoft for Windows 10 and Windows 11. It consists of a command-line utility and a set of services for installing applications.\\n\\nSetting\n```\nwinget settings\n```\\n\\nChoose store\\n\\n```\n-s msstore\n```\\n\\nList outdated packages\\n\\n```\nwinget upgrade\n```\\n\\nUpdate package\\n\\n```\nwinget upgrade <package name>\n```\\n\\nHow to update all packages\\n\\n```\nwinget upgrade --all\n```\\n\\nExport Installed Software list\\n\\n```\nwinget export -o <Path to JASON file>\n```\\n\\nImport Installed Software list\\n\\n```\nwinget import -i <Path to JASON file>\n```\\n\\nSearch for packages\\n\\n```\nwinget install Netflix\n```\\n\\nSource: https://docs.microsoft.com/en-us/windows/package-manager/"},{"title":"Cat A File With Line Numbers","category":"","tags":"Linux cat","url":"/2022-03-31-cat-a-file-with-line-numbers/","date":"2022-03-31","content":"You can use the <code>cat</code> command to view files, add line numbers with the '-n' flag and concatenate several files together. It's one of those simple tools that makes Linux so versatile.\\n\\nUse <code>cat</code> to view a file.\\n\\n```\\ndaniel@CShark:/mnt/d$ cat index.html\\n<html lang=\"en\">\\n<head>\\n<meta charset=\"utf-8\" />\\n <title>Hello World!</title>\\n <link rel=\"stylesheet\" href=\"hw.css\">\\n</head>\\n<body>\\n<div class=\"mainBox\">\\n <div class=\"textBox\">\\n <h1>Hello World!</h1>\\n </div>\\n <img src=\"hw.jpeg\" />\\n</div>\\n</body>\\n```\\nWith the <code>-n</code> flag you can view that file with line numbers.\\n\\n```\\ndaniel@CShark:/mnt/d$ cat -n index.html\\n 1 <html lang=\"en\">\\n 2 <head>\\n 3 <meta charset=\"utf-8\" />\\n 4 <title>Hello World!</title>\\n 5 <link rel=\"stylesheet\" href=\"hw.css\">\\n 6 </head>\\n 7 <body>\\n 8 <div class=\"mainBox\">\\n 9 <div class=\"textBox\">\\n 10 <h1>Hello World!</h1>\\n 11 </div>\\n 12 <img src=\"hw.jpeg\" />\\n 13 </div>\\n 14 </body>\\n```\\nUse <code>cat file1.txt file2.txt</code> if you want to view them as a single continuous file.\\n\\nUse <code>cat file1.txt file2.txt > combined.txt</code> if you want to create a new file with both of them combined."},{"title":"CPU stress tools","category":"","tags":"Linux Windows cpu Sysinternals","url":"/2022-02-27-CPU_Stress/","date":"2022-02-27","content":"There are many reasons why you may want to stress test the CPU on your system. You may want to see how your operating system and hardware perform when you are at full CPU utilization or you want to trigger resource monitoring alerts.\\n\\n# Linux\\n\\nstress\\n\\nEnter the following command where the number used in --cpu is the amount of threads to start. To fully stress the CPU, this should be the total number of CPU cores or double that if the CPU supports hyper-threading. You can obtain the appropriate number to use by entering getconf _NPROCESSORS_ONLN. \\n\\n```\nstress --cpu 8\n```\\n\\n# Windows\\n\\nCpuStres\\n\\n![CpuStres]( )\\n\\nhttps://docs.microsoft.com/en-us/sysinternals/downloads/cpustres"},{"title":"Clean Up Old Homebrew Files","category":"","tags":"Homebrew macOS","url":"/2022-01-31-cleanup_homebrew/","date":"2022-01-31","content":"Homebrew is a free, open-source software package management system that simplifies the installation of software on Apple’s macOS operating system and Linux.\\n\\nIf you've been using Homebrew for a while, you may have built up some cruft in the form old and outdated files. These will not be cleaned up automatically. You have do tell Homebrew to do so. This can be done with the following command.\\n\\n```\n$ brew cleanup\n```\\n\\nThis command will report what files it cleans up as well as how much disk space it was able to clear.\\n\\nYou can also scrub the cache, including downloads for even the latest versions and downloads for any installed formulae or casks.\\n\\n```\nrm -rf \"$(brew --cache)\"\n```"},{"title":"Install and Configure the AWS CLI on Windows","category":"","tags":"AWS CLI Windows install","url":"/2021-12-29-Install-and-Configure-the-AWS-CLI-on-Windows/","date":"2021-12-29","content":"Open the command prompt and run the following two commands:\\n\\n```\\nmsiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi\\n```\\n\\n```\\naws configure \\n```\\n\\nEnter the access key ID and secret access key with eu-west-1 as the region and json as the default output format.\\n\\nVerify if tools are installed:\\n\\n```\\naws --version\\n```\\n\\n# Testing\\n\\naws s3 ls\\n\\n# Notes\\n\\nRegion Name: EU (Frankfurt)\\nRegion Code: eu-central-1\\n\\nRegion: EU(Ireland)\\nRegion Code: eu-west-1"},{"title":"How to connect to an EC2 via SSH + troubleshooting","category":"","tags":"Linux AWS EC2 SSH","url":"/2021-11-30-How-to-connect-to-EC2-via-SSH/","date":"2021-11-30","content":"This note we will outline the steps to ensure a successful connection to your EC2 instance through SSH, as well as mention common troubleshooting techniques.\\n\\nIn general:\\n* Make sure the private key (pem file) on your Linux machine has 400 permissions or you will get an \"Unprotected private key file\" error.\\n* Make sure the username is given correctly when connecting via SSH, else you will get \"Host key not found\", \"Permission denied\", or \"Connection closed\" error.\\n\\nPossible reasons for \"Connection times out\" to EC2 instance via SSH:\\n* SG is not configured correctly\\n* NACL ist not configured correctly\\n* Check the route table for the subnet\\n* Instance doesn't have a public IP\\n"},{"title":"How to convert MBR 2 GPT in order to activate UEFI for Windows 11","category":"","tags":"Windows","url":"/2021-10-30-How-to-convert-MBR-2-GPT-in-order-to-activate-UEFI-for-Windows-11/","date":"2021-10-30","content":"In order to use Windows 11, UEFI + Secure Boot must be used. Fortunately, since Windows version 1703, it is no longer necessary to reinstall the operating system if you want to switch from BIOS (master boot record) to UEFI.\\n\\n## Verify\nFirst you have to check if you are still working with the legacy BIOS. This can be checked with the \"Disk Management\" tool as follows.\\n\\nRight-click on the Windows installation disk and select “Properties.”\\n\\n![Check-if-legacy-BIOS-DM]( )\\n\\n![check-mbr]( )\\n\\nIn the properties Window, go to the “Volumes” tab. You should see “Master Boot Record (MBR)” next to “Partition style”.\nIf it says “GUID Partition Table (GPT)”, then you’re already on UEFI and don’t need to do anything!\\n\\n## Convert Legacy BIOS to UEFI\\n\\nIn order to run the following commands, access the Command Prompt from Windows’s advanced startup (click on the “Restart” button while holding the Shift key).\\n\\nValidate if your disk can be converted.\\n\\n```\nmbr2gpt /validate\n```\\n\\nExecute the converting.\\n\\n```\nmbr2gpt /convert\n```\\n\\nAfter converting, restart your system and change your motherboard firmware settings from Legacy BIOS to UEFI.\\n\\nMore detailed information:\\n\\n`https://docs.microsoft.com/de-de/windows/deployment/mbr-to-gpt`"},{"title":"AWS S3 Presigned URL","category":"","tags":"AWS S3 CLI","url":"/2021-09-29-AWS-S3-Presigned-URL/","date":"2021-09-28","content":"If you want to provide temporary S3 access to an object that is otherwise private, then you can generate a presigned URL. The URL will be usable for a specified period of time, after which it will become invalid.\\n\\nThe following AWS CLI command will return a URL that includes the required authentication string. The authentication will become invalid after 10 minutes. The default expiration value is 3600 seconds.\\n\\nExp:\n```\naws s3 presign s3://BUCKETNAME/PrivateObject --expires-in 600\n```\\n\\nhttps://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html"},{"title":"Attach an AWS EFS Volume on Linux via IP","category":"","tags":"Linux AWS EFS NFS","url":"/2021-08-07-Attach_AWS_EFS_Volume_Linux_IP/","date":"2021-08-07","content":"Following a step-by-step process to attach an AWS EFS volume to a Linux system using an IP address.\\n\\n\\nCheck you current layout\\n\\n```\\nlsblk\\n```\\n\\nCreate montpoint/directory\\n\\n```\\nsudo mkdir /data\\n```\\n\\nAdd filesystem to fstab\\n\\n![EFS 1]( )\\n\\n\\nMount filesystem\\n\\n```\\nsudo mount -a\\n```\\n\\nValidate with mount\\n\\n```\\nmount\\n```\\n\\n![EFS 2]( )\\n\\n\\nValidate with df\\n\\n```\\ndf -h\\n```\\n\\n![EFS 3]( )"},{"title":"Formats of SSL/TLS certificates and their usage","category":"","tags":"SSL TLS","url":"/2021-07-29-Formats_of_SSL_certificates/","date":"2021-07-29","content":"The SSL/TLS certificates can be stored in several formats and also have different file extensions - e.g. pem, cer, der, pfx.\\n\\nWhat is the difference among certificates that can be stored as .p7b, .pfx, .p12, .pem, .der, .crt or .cer?\\n\\nThe file extension of SSL certificates ar not decisive. SSL certificate can be in text format (this is the most common - it is available on Linux and Apache, Unix and other servers) or binary (Java, Microsoft Server).\\n\\nIn text form, the certificate is stored in Base64 in a file. After opening this document - e.g. in Notepad - you will see its content encoded in Base64 and the footer/final line BEGIN/END CERTIFICATE.\\n\\n**PFX/P12/PKCS#12 format**\\n\\nThe PCKS#12 or PFX/P12 format represents a binary format for keeping the certificate (along with its intermediate) together with the private key. The certificates and the private key are password protected in the PFX file.\\n\\nThe most commonly used extension of the format is .pfx and .p12.\\nPKCS#12 is often used on the Windows devices for importing and exporting the certificates together with the private key.\\nThe certificates stored in PFX are also used for signing in Microsoft Authenticode.\\n\\n**PEM format**\\n\\nThis is the most widely used format for storing certificates. The majority of servers - e.g. Apache - work with the private key and the certificate in separate, independent files. We can often hear about the PEM certificate as the \"text format\" because it is encoded in Base64.\\nIt is a format encoded in Base64 with ASCII characters.\\nThe most commonly used extensions for these certificates are .cer, .crt, .pem or .key (for the private key).\\nApache and all servers on Unix/Linux OS assume this format.\\n\\n**DER format**\\n\\nThe DER format is a binary certificate format. It is not a text file and therefore it cannot be edited as text in Base64 (open in Notepad, copy, etc.).\\nAll certificate types and the private key can be stored in DER.\\nThe extension of DER certificates is usually .cer or .der.\\nThe DER format is used on the Java platforms.\\n\\n**Format P7B/PKCS#7**\\n\\nThe PCKS#7 or P7B format represents one or more certificates in the Base64 ASCII format stored in a file with the extension .p7b or .p7c.\\n\\nThe P7B file contains the certificate and its chain (the intermediate certificates), but the private key is not present in it.\\nThe P7B files are most commonly used on the Java Tomcat platform.\\n"},{"title":"How to uninstall the Cortana app with Powershell","category":"","tags":"Windows Powershell","url":"/2021-06-04-How_to_uninstall_the_Cortana_app/","date":"2021-06-04","content":"The following guide provides a simple and straightforward method to uninstall the Cortana app using Windows PowerShell.\\n\\n- Open the Start Menu and type in PowerShell.\\n- Right click on Windows PowerShell.\\n- Select 'Run as administrator'.\\n- Type the following text:\\n````powershell\\nGet-AppxPackage -allusers Microsoft.549981C3F5F10 | Remove-AppxPackage\\n````\\n- Press Enter.\\n"},{"title":"How to change the language of Visual Studio 2017/2019","category":"","tags":"VisualStudio","url":"/2021-05-23-Change_Language_in_Visual_Studio/","date":"2021-05-23","content":"In order to follow tutorials on the internet or threads on stackoverflow it is often time easier if you set the language in Visual Studio to English.\\n\\nHere is how to do it:\\n\\n1. Open the Visual Studio Installer.\n2. Click on change\n3. Click on the \"Language packs\" tab and select English\\n\\n4. Tools --> Options -> Environment --> International settings\n5. Select language"},{"title":"WSL - Upgrade Ubuntu to the latest release","category":"","tags":"Linux WSL Windows Ubuntu install","url":"/2021-04-11-WSL_Upgrade_Ubuntu_to_the_latest_release /","date":"2021-04-11","content":"Even if you use the distro apps for [WSL](https://danielschwensen.github.io/2019-04-07-Enable-Windows-Subsystem-for-Linux-on-Windows/) you can upgrade to the latest release.\\n\\nThe following steps did the trick:\\n\\nVerify your release before the upgrade\\n\\n```\\ncat /etc/lsb-release\\n```\\n\\n1. Apply all updates of installed packages\\n\\n```\\nsudo apt update\\nsudo apt upgrade -y\\n```\\n\\n2. Remove unused Kernels and install ‘update-manager-core’\\n\\n```\\nsudo apt --purge autoremove\\nsudo apt install update-manager-core -y\\n```\\n\\n3. Start Upgrade Process\\n\\n```\\nsudo do-release-upgrade\\n```\\n\\nAs the Linux environment apps such as Ubuntu or Debian do not support the Systemd that provides fundamental building blocks for a Linux operating system, we can’t use reboot or use the systemctl commands to manage the systemd services. \\nSo in order to restart WSL we need to restart the Lxssmanager service.\\n\\n```\\nGet-Service LxssManager | Restart-Service\\n```\\n\\nVerify your release after the upgrade\\n\\n```\\ncat /etc/lsb-release\\n```"},{"title":"Change Docker Default Location","category":"","tags":"Docker WSL Windows","url":"/2021-04-02-Change_Docker_Default_Location/","date":"2021-04-02","content":"Docker Desktop for Windows is great since you can switch between Linux and Windows seamlessly.\\n\\nUnfortunately, during the installation, you are not offered the possibility to set the default directory. \\nThis leads to the system drive filling up sooner or later if you do a lot of experimenting.\\n\\n \\nFollowing how to change the default location:\\n\\n\\n# Windows\\n\\n \\nDefautl location: %PROGRAMDATA%/Docker\\n \\n1. Stop Docker\\n2. Create new destination on different drive\\n\\n```\\nmkdir D:\\Docker_Windows\\n```\\n\\n3. Add \"data-root\": \"D:\\\\Docker_Windows\" to C:\\ProgramData\\Docker\\config\\daemon.json\\n4. Start Docker\\n\\n\\n# Linux\\n\\n \\nDefault location: %LOCALAPPDATA%/Docker \\n \\n1. Stop Docker\\n2. Shutdown all WSL distros\\n```\\nwsl --shutdown\\n```\\n3. Export docker-desktop-data to tar file\\n```\\nwsl --export docker-desktop-data D:\\docker-desktop-data.tar\\n```\\n4. Unregister current docker-desktop-data distro\\n```\\nwsl --unregister docker-desktop-data\\n```\\n5. Import docker-desktop-data distro from tar file\\n```\\nwsl --import docker-desktop-data D:\\Docker_WSL\\data D:\\docker-desktop-data.tar --version 2\\n```\\n6. Start Docker\\n7. Remove D:\\docker-desktop-data.tar (if the import was successful)"},{"title":"Search Google Like a Pro","category":"","tags":"Google search","url":"/2021-03-13-Search-Google-like-a-pro/","date":"2021-03-13","content":"The Google search operators are special search commands, sometimes called advanced operators, that allow you to set specific restrictions or get specific types of results from your Google search. Once you’ve mastered just a few of these special commands, you’ll wonder how you ever managed without them.\\n\\nUse the keyword **related:** to find similar websites.\\n\\n```\nrelated:cnn.com\n```\\n\\nUse **site:** to limit your search to a single domain\\n\\n```\nsite:stadt-bremerhaven.de apple\n```\\n\\nUse **stocks:** to get stock information\\n\\n```\nstocks:Microsoft\n```\\n\\nUse the keyword **before:** to travel back in time\\n\\n```\nPowershell before:2010\n```\\n\\nUse the operator **\\-** to exclude a word\\n\\n```\nweb development -Python\n```\\n\\nUse the operator **\\*** to replace missing words\\n\\n```\n*oriented programming in python\n```\\n\\nIf you're looking for a definition of a word, use the keyword **define:**\\n\\n```\ndefine: object oriented programming\n```\\n\\nUse **site:** to search for a particular website or content\\n\\n```\nsite: web dev blog post\n```"},{"title":"How to determine the total size of a directory from the command line","category":"","tags":"Linux du cli","url":"/2021-02-28-determine_the_total_size _of_a_directory/","date":"2021-02-28","content":"The command du \"summarizes disk usage of each FILE, recursively for directories,\" e.g.\\n\\n```\ndu -hs /path/to/directory\n```\\n\\n-h is to get the numbers \"human readable\", e.g. get 140M instead of 143260 (size in KBytes)\\n\\n-s is for summary (otherwise you'll get not only the size of the folder but also for everything in the folder separately)\\n\\nList of all the folders in /path/to/folder and their sizes.\n```\ndu -h --max-depth=1 /path/to/folder\n```\\n\\nList from smallest to largest.\n```\ndu -h --max-depth=1 /path/to/folder | sort -nk1 ```"},{"title":"Change Font Size in Git Bash (MINGW64)","category":"","tags":"Git","url":"/2021-01-04-Change_Font_Size_in_Git_Bash/","date":"2021-01-04","content":"If the font size is too small after installing Git Bash (MINGW64), then it can be changed as follows.\\n\\n1. Right click on the upper left corner of the Git Bash window and choose \"Options\". ![Git Bash 1]( )\\n\\n ![Git Bash 2]( ) 2. Select \"Text\" and click on \"Select\". 3. Choose your prefered size and confirm with OK.\\n\\n ![Git Bash 3]( ) 4. Save."},{"title":"Get Hard Drive Information Using Powershell","category":"","tags":"Powershell","url":"/2020-12-23-Get_Hard_Drive_Information_Using_Powershell/","date":"2020-12-23","content":"On Windows you can use Powershell to obtain information about disks and partitions, apart from the classic tools like the Disk Management Utility or Diskpart.\\n\\nThe corresponding Powershell cmdlets can be retrieved with the following command:\\n\\n````powershell Get-Command -Module Storage -Name Get*\n````\\n\\n* **Get-PhysicalDisk** allows you to get information about physical disks and device characteristics. * **Get-Disk display** gets disk information at the logical level of the operating system. * **Get-Partition** shows partition information on all drives. * **Get-Volume** displays volume information on all disks.\\n\\nExp.\\n\\n```powershell\nGet-PhysicalDisk |ft -Wrap\n```\n![Get-PhysicalDisk]( )\\n\\n```powershell\nGet-Disk\n```\n![Get-Disk]( )\\n\\n```powershell\nGet-Partition\n```\n![Get-Partition]( )\\n\\n```powershell\nGet-Volume\n```\n![Get-Volume]( )"},{"title":"How to Split a File Path with Powershell","category":"","tags":"Powershell","url":"/2020-12-12-Split_File_Path/","date":"2020-12-12","content":"When working with file names, it is sometimes necessary to extract the individual parts such as drive, path or name from them.\\n\\nThe following examples are mostly based on the $PROFILE path\\n\\n````powershell ❯ $PROFILE\nF:\\OneDrive\\Dokumente\\PowerShell\\Microsoft.PowerShell_profile.ps1\n````\\n\\nDefault Split-Path command retrieves the parent folder name of the file.\\n\\n```powershell\n❯ Split-Path $PROFILE\nF:\\OneDrive\\Dokumente\\PowerShell\n```\\n\\nThe default parameter is -Parent\\n\\n```powershell\n❯ Split-Path $PROFILE -Parent\nF:\\OneDrive\\Dokumente\\PowerShell\n```\\n\\nGet the qualifier of a path\\n\\n```powershell\n❯ Split-Path $PROFILE -Qualifier\nF:\n```\\n\\nUse the -Leaf parameter if you only need file name\\n\\n```powershell\n❯ Split-Path $PROFILE -Leaf\nMicrosoft.PowerShell_profile.ps1\n```\\n\\nGet all file names in a directory\\n\\n```powershell\n❯ Split-Path (Get-ChildItem -Path E:\\temp\\ -File) -Leaf -Resolve\n1 (1).txt\n1 (2).txt\n56.txt\nasci_fun.txt\nasci_fun2.txt\n```\\n\\nThis can be done by Get-ChildItem only\\n\\n```powershell\n❯ gci E:\\temp\\ -Name -File\n1 (1).txt\n1 (2).txt\n56.txt\nasci_fun.txt\nasci_fun2.txt\n```"},{"title":"Install and configure AWS CLI on CentOS","category":"","tags":"AWS CentOS CLI Linux install","url":"/2020-12-10-AWS_CLI_on_CentOS/","date":"2020-12-10","content":"Following the process of installing and configuring the Amazon Web Services (AWS) Command Line Interface (CLI) on a CentOS operating system.\\n\\n````bash\\nsudo yum install epel-release\\nsudo yum install python-pip\\nsudo pip install awscli\\n````\\n\\nRun aws configure and enter the access key ID and secret access key you noted down earlier in the lesson, with us-east-1 as the region and json as the default output format.\\n\\n# Testing\\n\\n````bash\\naws s3 ls\\n````"},{"title":"Make your terminal look great again","category":"","tags":"Powershell Windows terminal posh-git oh-my-posh GoMono nerdfonts","url":"/2019-12-26-make your terminal look great again/","date":"2019-12-26","content":"If you want to make your Windows Terminal look great again then this brief article is for you.\\n\\n![Windows Terminal]( )\\n\\nInstall posh-git and oh-my-posh:\\n\\n````powershell Install-Module posh-git -Scope CurrentUser\nInstall-Module oh-my-posh -Scope CurrentUser\n````\\n\\nIn case you're running this on PS Core, make sure to also install version 2.0.0-beta1 of PSReadLine\\n\\n````powershell Install-Module -Name PSReadLine -AllowPrerelease -Scope CurrentUser -Force -SkipPublisherCheck\n````\nAdd the following to you profile (notepad $profile)\\n\\n````powershell Import-Module posh-git\nImport-Module oh-my-posh\nSet-Theme Paradox\n````\nInstall fonts which includes glyphs and configure your Windows Terminal profile accordingly.\\n\\nI personally use GoMono NF\\n\\nhttps://www.nerdfonts.com/font-downloads"},{"title":"A Quick Guide to Identifying Installed .NET Framework Versions","category":"","tags":"Powershell Windows","url":"/2019-11-21-determine_dot_net_versions/","date":"2019-11-21","content":"As developers, understanding which versions of the .NET Framework are installed on a system can be crucial for various tasks. Whether you're debugging, deploying, or setting up a new environment, knowing the exact versions at hand can save time and prevent compatibility issues. Following two simple methods – using Powershell and the Registry Editor – to help you pinpoint all the .NET versions installed on your machine.\\n\\n**Powershell** \\n\\n````powershell \\ngci $env:Windir\\Microsoft.Net\\framework | Where {$_.Mode -match \"d\"} | ft -auto\\n````\\n\\n**Registry Editor**\\n\\nTo find .NET Framework versions by viewing the registry (.NET Framework 1-4)\\n\\n- On the Start menu, choose Run.\\n- In the Open box, enter regedit.\\n- In the Registry Editor, open the following subkey: HKLM\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\n\\nThe installed versions are listed under the NDP subkey. The version number is stored in the Version entry. For the .NET Framework 4 the Version entry is under the Client or Full subkey (under NDP), or under both subkeys.\\n"},{"title":"Enable Windows Sandbox with PowerShell","category":"","tags":"Powershell Windows","url":"/2019-11-19-windows_sandbox/","date":"2019-11-19","content":"Windows Sandbox is perfect if you need to download and install an unknown executable in an isolated, temporary desktop environment where you can run untrusted software without the fear of lasting impact to your PC.\\nAny software installed in Windows Sandbox stays only in the sandbox and cannot affect your host. Once Windows Sandbox is closed, all the software with all its files and state are permanently deleted.\\n\\nFeatures:\\n\\n- Part of Windows – everything required for this feature ships with Windows 10 Pro and Enterprise. No need to download a VHD!\\n- Windows Sandbox runs as a clean new installation of Windows\\n- Disposable – nothing persists on the device; everything is discarded after you close the application\\n- Secure – uses hardware-based virtualization for kernel isolation, which relies on the Microsoft’s hypervisor to run a separate kernel which isolates Windows Sandbox from the host\\n- Efficient – uses integrated kernel scheduler, smart memory management, and virtual GPU\\n\\nWindows Sandbox has the following pre-requisites:\\n\\n- Windows 10 Pro or Enterprise build 18305 or later\\n- AMD64 architecture\\n- Virtualization capabilities enabled in BIOS\\n\\nEnable Windows 10 Sandbox via PowerShell\\n\\nNote!\\nBefore proceeding, you need to enable virtualization, as follows:\\n\\n- If you are using a physical machine, ensure virtualization capabilities are enabled in the BIOS.\\n- If you are using a virtual machine, enable nested virtualization with the following PowerShell command:\\n\\n````powershell\\nSet-VMProcessor -VMName <VMName> -ExposeVirtualizationExtensions $true\\n````\\n\\nEnable Sandbox as Admin:\\n\\n````powershell\\nEnable-WindowsOptionalFeature -FeatureName \"Containers-DisposableClientVM\" -All -Online\\n````\\n\\nNow you can search (Windows + Q) for Sandbox and open it.\\n\\n![Sandbox](/assets/2019/11/sandbox.png)\\n"},{"title":"Get a Docker based Wordpress playground in a heartbeat","category":"","tags":"Docker Wordpress docker-compose MySQL Powershell","url":"/2019-08-31-wordpress-docker-playground/","date":"2019-08-31","content":"Do you want to test the latest Wordpress version (including plug-ins and themes) without having to install a full development environment (Apache, MySQL,PHP etc.)?\\nIf so, then Docker offers a simple solution to quickly commission and de-commission a WordPress \\+ MySQL development environment in no time.\\n\\n## Requirements\\n\\n* [Docker](https://www.docker.com/)\\n* Docker Compose\\n* Powershell\\n\\n## Installation & Configuration\\n\\n1.\\nStart Powershell, create a directory and install the docker-compose.yaml file found in this [Github repository](https://github.com/danielschwensen/wordpress-docker-playground). \\n\\nYou can get it via: \\n\\n git clone https://github.com/danielschwensen/wordpress-docker-playground.git\\n \\n or\\n\\n wget -uri https://raw.githubusercontent.com/danielschwensen/wordpress-docker-playground/master/docker-compose.yaml -OutFile docker-compose.yaml\\n\\n2.\\nStart the show by running the command `docker-compose up`.\\n\\nThis will launch the two containers and link them together. You will see logging to your terminal window. You can press Ctrl+C to stop the containers and get your command prompt back. To launch the containers in the background add a \"-d\".\\n\\n3.\\nConnect to your new WordPress server at http://localhost:8080/\\n\\nThat's it.\\n\\nNow you simply go through the normal WordPress installation process and within a few screens your new site will be fully active. \\n\\n`docker-compose stop` will stop the containers from running. Doing `docker-compose start` will start them up again.\\n\\nWHEN YOU ARE DONE and want all this to go away, just type `docker-compose down` and the services will be stopped and the containers removed."},{"title":"How to Backup your Raspberry Pi SD Card on Windows?","category":"","tags":"Raspberry_Pi","url":"/2019-07-17-How to Backup your Raspberry Pi SD Card/","date":"2019-07-17","content":"If, like me, you want to try out new software or install the latest operating system version directly, it makes a lot of sense to back up the SD card of your Raspberry Pi regularly so that the system can be restored quickly in case of an emergency.\\n\\nBy the way: The regular backup of the most important files is unaffected by this.\\n\\nTo back up our Raspberry Pi’s SD Card on Windows I recommend utilizing the imaging tool that is called [win32diskimager](https://sourceforge.net/projects/win32diskimager/).\\n\\nWin32diskimager is a useful tool that can read and write images to USB Sticks or SD/CF Cards.\\n\\n**Shutdown**\\n\\nYou should shutdown you system with the command `sudo shutdown -h now` to ensure that the system is stopped properly.\\nIt will do the following steps to ensure the operating system shutdowns gracefully.\\n\\n1. It will send SIGTERM to all the running processes, so they can save and exit gracefully.\\n2. After an interval, it sends SIGKILL, so that any remaining processes will be halted.\\n3. Lastly, it will unmount all the file systems.\\n4. The screen will now show System Halted.\\n5. You can now remove the power cord with minimal risk to your Raspberry Pi and the operating system.\\n\\n**Backing up your Raspberry Pi SD Card on Windows**\\n\\n1. Start _win32diskimager_\\n2. Define Image File like _MyPiBacku.img_\\n3. Select Device (if your Pi has multiple partitions, select the first one -the process will still clone the full SD card and not just the single partition) \\n4. Click on Read (this step can take some time)\\n\\nThat's it. The restore process is - you guessed it - just the other way around"},{"title":"What Linux Distro Am I Running?","category":"","tags":"Linux","url":"/2019-07-14-What Linux Distro Am I Running/","date":"2019-07-14","content":"If you work in a large company (and are more likely to work with Windows operating systems), you may end up on an unknown Linux system for troubleshooting purposes. To quickly find out which distribution is installed, the following commands may be helpful:\\n\\nViewing the release files:\\n\\n```\\n$ cat /etc/*release*\\nDISTRIB_ID=Ubuntu\\nDISTRIB_RELEASE=18.04\\nDISTRIB_CODENAME=bionic\\nDISTRIB_DESCRIPTION=\"Ubuntu 18.04.2 LTS\"\\nNAME=\"Ubuntu\"\\nVERSION=\"18.04.2 LTS (Bionic Beaver)\"\\nID=ubuntu\\nID_LIKE=debian\\nPRETTY_NAME=\"Ubuntu 18.04.2 LTS\"\\nVERSION_ID=\"18.04\"\\nHOME_URL=\"https://www.ubuntu.com/\"\\nSUPPORT_URL=\"https://help.ubuntu.com/\"\\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\\nVERSION_CODENAME=bionic\\nUBUNTU_CODENAME=bionic\\n```\\nOr try it with the issue files, if there wasn't a release file:\\n\\n```\\n$ cat /etc/*issue*\\nUbuntu 18.04.2 LTS \\n \\l\\n\\nUbuntu 18.04.2 LTS\\n```\\n\\nIf you don't want to rely on files then you can use tools as well:\\n\\n**lsb_release**\\n\\nThe **_lsb_release_** command gives LSB (Linux Standard Base) and distribution-specific information on the CLI.\\n\\n```\\n$ lsb_release -a\\nNo LSB modules are available.\\nDistributor ID: Ubuntu\\nDescription: Ubuntu 18.04.2 LTS\\nRelease: 18.04\\nCodename: bionic\\n```\\n\\n**hostnamectl**\\n\\n**_hostnamectl_** runs only on **_systemd_** based Linux distributions.\\n\\n```\\n$ hostnamectl\\n Static hostname: ip-10-0-1-10\\n Icon name: computer-vm\\n Chassis: vm\\n Machine ID: f89138299a734aec9037cb36dcca0fa2\\n Boot ID: 37b19f42a105438e8cd113c0f9c38e78\\n Virtualization: xen\\n Operating System: Ubuntu 18.04.2 LTS\\n Kernel: Linux 4.15.0-1034-aws\\n Architecture: x86-64\\n```\\n\\n**uname**\\n\\nIf you just want to print the kernal version.\\n\\n```\\n$ uname -r\\n4.19.57-v7+\\n```"},{"title":"Markdown Cheatsheet","category":"","tags":"markdown cheatsheet","url":"/2019-04-12-markdown/","date":"2019-04-12","content":"Markdown is a lightweight and easy-to-use syntax for styling all forms of writing.\\n\\nYou control the display of the document; formatting words as bold or italic, adding images, and creating lists are just a few of the things we can do with Markdown. Mostly, Markdown is just regular text with a few non-alphabetic characters thrown in, like `#` or `*`.\\n\\n\\n# Headers\\n\\n````\\n# H1\\n## H2\\n### H3\\n#### H4\\n##### H5\\n###### H6\\n\\n````\\n\\n# H1\\n## H2\\n### H3\\n#### H4\\n##### H5\\n###### H6\\n\\n# Emphasis\\n\\n\\n````\\nBold with **asterisks** \\n\\nItalic with _underscores_.\\n\\nCombined with **asterisks and _underscores_**.\\n\\nStrikethrough uses two tildes. ~~Scratch this.~~\\n\\n````\\n\\nBold with **asterisks** \\n\\nItalic with _underscores_.\\n\\nCombined with **asterisks and _underscores_**.\\n\\nStrikethrough uses two tildes. ~~Scratch this.~~\\n\\n# Links\\n\\n````\\n[Visit Wikipedia](www.wikipedia.com) \\n\\n````\\n\\n[Visit Wikipedia](www.wikipedia.com) \\n\\n\\n# Blockquotes\\n\\nTo create a block quote, all you have to do is preface a line with the \"greater than\" caret (>).\\nYou can also place a caret character on each line of the quote. This is particularly useful if your quote spans multiple paragraphs.\\n\\n>block quote\\n\\n# Lists\\n\\nTo create an unordered list, you'll want to preface each item in the list with an asterisk ( * ). Each list item also gets its own line. For example, a grocery list in Markdown might look like this:\\n* Milk\\n* Eggs\\n* Salmon\\n* Butter\\n\\n````\\n* Milk\\n* Eggs\\n* Salmon\\n* Butter\\n````\\n\\nOccasionally, you might find the need to make a list with more depth, or, to nest one list within another. Have no fear, because the Markdown syntax is exactly the same. All you have to do is to remember to indent each asterisk one space more than the preceding item.\\nFor example, in the following list, we're going to add some sub-lists to each \"main\" list item, describing the people in detail:\\n\\n * Tintin\\n * A reporter\\n * Has poofy orange hair\\n * Friends with the world's most awesome dog\\n* Haddock\\n * A sea captain\\n * Has a fantastic beard\\n * Loves whiskey\\n\\n````\\n * Tintin\\n * A reporter\\n * Has poofy orange hair\\n * Friends with the world's most awesome dog\\n* Haddock\\n * A sea captain\\n * Has a fantastic beard\\n * Loves whiskey\\n ````\\n\\n# Tables\\n\\n![Markdown Table](/assets/2019/04/20190412-MarkdownTable.jpg)\\n\\n| Day | Subject | Time|\\n|-----|---------|-----|\\n|Monday|C#|2h|\\n|Tuesday|Powershell|1h|\\n\\n\\n\\n\\n# Syntax Highlight\\n\\nA code block by indentation with four spaces\\n\\n Code Block\\n more code\\n\\nAlternatively, you can use 3 backtick quote marks before and after the block, like this:\\n\\n\\```\\n\\nThis is a code block\\n\\n\\```\\n\\n```\\nThis is a code block\\n```\\n\\nTo add syntax highlighting to a code block, add the name of the language immediately\\nafter the backticks: \\n\\n\\```csharp\\n\\n\\n\\n\\```\\n\\n\\n```csharp\\npublic Task<string> GetValueAsync(int key)\\n{\\n string result;\\n if (cache.TryGetValue(key, out result))\\n return Task.FromResult(result);\\n return DoGetValueAsync(key);\\n}\\n```\\n\\n\\n# Inline code characters\\n\\nUse the backtick to refer to a \\`function()\\`.\\n\\nUse the backtick to refer to a `function()`.\\n\\n# Escaping\\n\\nBackslash (\\\\) escapes the following characters:\\\\n\\ ` * _ { } [ ] ( ) # + - . !\\n\\n\\\\*this text is surrounded by literal asterisks\\*\\\\n\\n"},{"title":"Enable Windows Subsystem for Linux on Windows","category":"","tags":"Linux Windows WSL","url":"/2019-04-07-Enable Windows Subsystem for Linux on Windows/","date":"2019-04-07","content":"The Windows Subsystem for Linux lets developers run a Linux environment - including most command-line tools, utilities, and applications - directly on Windows, unmodified, without the overhead of a virtual machine.\\n\\n1. To enable Windows Subsystem for Linux (WSL) on your computer, you need to run the following powershell command as an admin:\\n\\n````powershell\nEnable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux\n````\\n\\n2. Restart your computer when prompted\\n\\n## Install a Linux distribution\\n\\nThere are several Linux distributions available to run on WSL. You can find and install your favorite in the Microsoft Store.\\n\\n**[Ubuntu](https://www.microsoft.com/store/p/ubuntu/9nblggh4msv6)**\\n\\n### Set up your account\\n\\nAfter the Linux distribution has installed, open it. You can do this by entering WSL from the Start menu. You'll be prompted to create an account name and password when you run a distribution for the first time. After this first time, when you start the distribution, you'll be signed in as this normal (non-admin) user by default.\\n\\n{: .box-note}\n**Note:** You can choose any user name and password. They have no bearing on your Windows user name. After you create the user account, you won't be prompted for your password when using the distribution, unless you elevate a process by using the sudo command. Sudo stands for \"SuperUser Do\" and is used for any task requiring root admin privilege, like installing tools or frameworks.\\n\\n### Update your distribution\\n\\n````bash\nsudo apt update && sudo apt upgrade -y\n````\\n\\n## Use Linux commands and work across Windows and Linux file systems\\n\\nYou can also run your Linux distribution path right inside the Windows command prompt (or in PowerShell), by entering wsl.exe or bash.exe. These commands will switch to a display of the Linux command line, using the path for your current directory. This path will appear to be in a mounted folder, /mnt/c, because we're now viewing your Windows C:\\ drive folder from the Linux subsystem. You can access all of your local computer's file system from within the Linux shell by using this /mnt/c mounted file path.\\n\\n## Change the default terminal shell to WSL\\n\\nIn VS Code, select View > Terminal (or select Ctrl+`, using the backtick character). A command-line (or terminal shell) window will open at the bottom of your VS Code window. This window lets you run Node.js and other command-line tools without leaving VS Code. The default terminal is PowerShell.\\n\\nTo change the default VS Code terminal shell, select Customize. A settings window with a list of options will open. Select WSL Bash in the list. (If the Customize button doesn't appear, select the F1 key and enter Terminal: Select Default Shell.)\\n\\n## WSL Config\\n\\nWSL Config (wslconfig.exe) is a command-line tool for managing Linux distributions running on WSL. You can use it to list available distributions, set a default distribution, and uninstall distributions. To see the available options for WSL Config, enter wslconfig.exe /? in your Windows command prompt or in PowerShell.\\n\\n## Install another Linux distribution and set a new default\\n\\n1. To see a list of the Linux distributions you currently have installed, open PowerShell and enter wslconfig.exe /list. You will probably only see Ubuntu (default).\n2. Let's install another distribution from Microsoft Store. To install the distribution, go to Debian GNU/Linux. Select the Get button, wait for the distribution to install, and then select Launch.\n3. After the new distribution starts, it will prompt you to choose a new UNIX user name and password. After you do so, open PowerShell again and enter wslconfig.exe /list. You should now see your multiple Linux distributions represented, including an indicator that your Ubuntu distribution is still set to be the default for use with commands in PowerShell, like wsl.exe.\n4. Set the new Debian distribution to be the default when running WSL on the command line (or in PowerShell) by using wslconfig.exe /setdefault Debian. Run wslconfig /list again and make sure that Debian is now marked as the default.\nNow if you're using PowerShell and enter wsl, you'll open a Debian distribution command prompt rather than a Ubuntu command prompt.\n5. If you no longer want the Debian distribution installed on your computer, you can unregister it by using wslconfig.exe /unregister Debian.\\n\\nNote that when you unregister a Linux distribution, all data, settings, and software associated with that distribution will be permanently lost. Reinstalling from Microsoft Store will install a clean copy.\\n\\nRelated article\n[WSL - Upgrade Ubuntu to the latest release](https://danielschwensen.github.io/2021-04-11-WSL_Upgrade_Ubuntu_to_the_latest_release/)"},{"title":"How to compile a C# source file without Visual Studio","category":"","tags":"C# .NET csc","url":"/2018-09-02-compile-cSharp-source-file/","date":"2018-09-02","content":"You don't need Visual Studio to compile C# source code. Although VS is largely available I find it interesting to know how you can compile a simple source file to an executable file without it.\\n\\nAll you need is a text editor and a C# compiler. Luckily, both ships with Windows 10.\\n\\n## Compiler\\n\\nThe compiler csc.exe is located:\\n\\nC:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319\\n\\n## Example\\n\\nFollowing an example (assuming you have added this location to your Windows PATH environment variable):\\n\\ncsc /t:exe EuroDollar.cs\\n\\nwould produce EuroDollar.exe in a snap.\\n\\nFollowing the code of EuroDollar.cs\\n\\n \\nusing System;\\n\\nclass Konsolendemo\\n{\\n static void Main()\\n {\\n int i;\\n Console.WriteLine(\"Euro --> Dollar Calculator\\n\");\\n do\\n {\\n float rate, euro, dollar;\\n Console.WriteLine(\"Please enter the current dollar exchange rate: \");\\n rate = Convert.ToSingle(Console.ReadLine());\\n Console.Write(\"How many Euros would you like to change? \");\\n euro = Convert.ToSingle(Console.ReadLine());\\n dollar = euro * rate;\\n Console.WriteLine(\"You get \" + dollar.ToString(\"0.00 $\"));\\n Console.WriteLine(\"Terminate? (j/n)\");\\n string s = Console.ReadLine();\\n i = string.Compare(s,\"j\");\\n } while (i != 0);\\n }\\n}\\n \\n\\n"},{"title":"Installing Packer on CentOS","category":"","tags":"Packer code Linux install","url":"/2018-08-26-installingPacker/","date":"2018-08-26","content":"For those venturing into the world of automated machine image creation, HashiCorp's Packer offers a versatile tool to make the process efficient and consistent. While there are various operating systems and platforms on which one might install Packer, this post specifically focuses on CentOS 7.\\n\\nRequirements:\\n- unzip\\n- wget\\n\\n## Installing Packer\\n\\nMove to /usr/local/bin, download and unpack packer.\\n\\n\\n \\ncd /usr/local/bin/\\nwget https://releases.hashicorp.com/packer/1.2.5/packer_1.2.5_linux_amd64.zip\\nunzip packer_1.2.5_linux_amd64.zip\\nrm -f packer_1.2.5_linux_amd64.zip\\ncd\\npacker --version\\n \\n\\nNow you can start creating a template.\\n"},{"title":"Create Vagrant Box from Scratch","category":"","tags":"Vagrant code Linux install","url":"/2018-08-25-createVagrantBoxFromScratch/","date":"2018-08-25","content":"The world of virtualization offers countless possibilities, allowing developers and system administrators to replicate environments, test software configurations, and more, all without needing physical machines. One of the most powerful tools in this space is Vagrant. Although it’s primarily used for provisioning and managing virtual machines (VMs), a frequently asked question is: How do you create your own Vagrant box? In this blog post, we'll be diving deep into this topic. Starting with the basics, we will craft a custom Vagrant box using VirtualBox and an Ubuntu 18.04, Bionic Beaver base image. Whether you're new to Vagrant or looking to expand your toolkit, this step-by-step guide will walk you through the process from start to finish.\\n\\n## Requirements\\n\\nVirtual Box and Vagrant needs to be installed and configured first!\\n\\nI am gonna be using the Ubuntu base image \"Ubuntu 18.04, Bionic Beaver\"\\n\\nCreate a new folder were you can store your OS image and Vagrant file.\\n\\n\\n \\nmkdir VagrantUbuntuBox\\ncd VagrantUbuntuBox\\n \\n\\nDownload the iso\\n\\n \\ncurl http://archive.ubuntu.com/ubuntu/dists/bionic/main/installer-amd64/current/images/netboot/mini.iso -o Ubuntu-mini.iso\\n \\n\\n\\n## Virtual Box\\n\\nCreate a new vm\\n\\n![01]( )\\n\\n![02]( )\\n\\n![03]( )\\n\\n![04]( )\\n\\n![05]( )\\n\\n\\n## VM Settings\\n\\nDisable audio and USB.\\n\\nSet network to NAT and add port forwarding for SSH.\\n\\n![06]( )\\n\\nSelect your iso image.\\n\\n![07]( )\\n\\nStart the vm and confirm the default settings during the installation.\\n\\nuser = vagrant\\n\\npw = vagrant\\n\\nUse entire disk\\n\\nInstall automatic updates\\n\\n![08]( )\\n\\nDon't forget to remove the iso, after finishing the installation.\\n\\nNow you should be able to log in with user vagrant\\n\\n![09]( )\\n\\nAlthough vagrant is a superuser you don't want to type sudo < command > all the time.\\n\\nTo prevent that:\\n\\n \\nsudo su -\\nvisudo -f /etc/sudoers.d/vagrant\\n \\n\\nand add\\n\\n \\nvagrant ALL=(ALL) NOPASSWD:ALL\\n \\n\\nAdding insecure Keypair from https://raw.githubusercontent.com/hashicorp/vagrant/master/keys/vagrant.pub\\n\\n \\nmkdir /home/vagrant/.ssh\\nchmod 0700 /home/vagrant/.ssh\\ncd /home/vagrant/.ssh\\nwget https://raw.githubusercontent.com/hashicorp/vagrant/master/keys/vagrant.pub\\nmv vagrant.pub authorized_keys\\nchmod 0600 authorized_keys\\ncd ../\\nchown -R vagrant .ssh/\\n \\n\\n## SSH CONFIG\\n\\nopen\\n\\n```\\nvi /etc/ssh/sshd_config\\n```\\n\\nand add to the end of the file\\n\\n```\\nAuthorizedKeysFile %h/.ssh/authorized_keys\\n```\\n\\nRestart the ssh service\\n\\n```\\nservice ssh restart\\n```\\n\\nInstall the following additional packages\\n\\n```\\napt-get install -y gcc build-essential git linux-headers-$(uname -r) dkms\\n```\\n\\n## Install Virtual Box Guest Additions\\n\\nInsert Guest Additions CD image from Devices menu\\n\\n \\nmount /dev/cdrom /mnt\\ncd /mount\\n./VBoxLinuxAdditions.run\\n \\n\\nZero out the disk to fix fragmentation issues and to compress the disk easier\\n\\n \\ndd if=/dev/zero of=/EMPTY bs=1M\\nrm -f /EMPTY\\n \\n\\n## Create your box\\n\\n![10]( )\\n![11]( )\\n\\nRun\\n\\n \\nvagrant init ubuntu64 -m\\nvagrant up\\n \\n\\n![12]( )\\n\\nYou now should be able to access your box via ssh\\n\\n \\nvagrant ssh\\n"},{"title":"How to install and access MySQL on Qnap","category":"","tags":"MySQL MariaDB Qnap install","url":"/2018-02-09-mysqlonqnap/","date":"2018-02-09","content":"This note covers the necessary steps to get started, including the installation of MariaDB via the App Center, enabling MySQL, and setting up default username and password. Whether you're planning to administer your databases through phpMyAdmin or Workbench, this guide will provide you with a step-by-step instructions.\\n\\nInstall MariaDB via App Center\\n\\n![MariaDB]( )\\n\\nEnabling MySQL\\n\\n![EnablingMySQL]( )\\n\\nQNAP Default Username/Password for MySQL\\n\\nThe default username for MySQL on your QNAP is “root” and the default password is “admin“.In case you changed the password of root and forgot what it was;\\nIn the “Applications” → “SQL Server” page a “Reset root password” will allow you to reset it to it’s defaults.\\n\\n## phpMyAdmin\\n\\nAlso, you need to install phpMyAdmin in order to administer your databases with a web browser.\\n\\n![My helpful screenshot]( )\\n\\nAccess: http://`<ip of your Qnap>`/phpMyAdmin\\n\\n## Workbench\\n\\nAnother option would be Workbench. MySQL Workbench provides data modeling, SQL development, and comprehensive administration tools for server configuration, user administration, backup, and much more.\\n\\nhttps://www.mysql.com/de/products/workbench/\\n\\nNote!\\nBy default, MariaBD only allows connections from localhost. In order to allow connections from remote hosts, you have to add a user that is allowed to connect from something other than 'localhost'.\\n\\nExp:\\n\\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'192.168.100.%' IDENTIFIED BY 'my-new-password' WITH GRANT OPTION;\\n\\nThis commant grants user 'root' permissions to connect from anywhere on the 192.168.100.0/24 LAN.\\n\\n## SSH\\n\\nBear in mind that only the user admin is allowed to connect via ssh to your Qnap device - if ssh is enabled.\\n\\n![EnableSSH]( )\\n"},{"title":"WinSCP Backup","category":"","tags":"Powershell backup code WinScp FTP Windows","url":"/2018-01-28-winscp/","date":"2018-01-28","content":"If you're like me, you've often forgotten to back up your WinSCP settings. Not anymore! Today, I've finally taken the plunge and added a simple solution to my backup script. It's a quick and painless way to ensure you never lose your settings again.\\n\\n \\n<#\\n.SYNOPSIS\\nThis script backs up WinSCP settings by exporting the relevant registry key.\\n\\n.DESCRIPTION\\nExports the WinSCP registry key and saves it with a timestamp to a specified backup location.\\n\\n.PARAMETER BackupPath\\nThe path where the backup should be saved.\\n\\n.EXAMPLE\\n.\\Backup-WinSCP.ps1 -BackupPath \"C:\\Backups\"\\n#>\\n\\n[CmdletBinding()]\\nparam(\\n [Parameter(Mandatory = $false)]\\n [string]$BackupPath = 'C:\\YourBackupFolder'\\n)\\n\\nfunction Export-WinSCPSettings {\\n # Define the WinSCP registry key and backup file name\\n $WinScpExportRegKey = \"HKCU\\Software\\Martin Prikryl\"\\n $WinScpstrExportFileName = \"WinScpSettings_$(get-date -f yyyyMMddHHmmss).reg\"\\n $WinScpExportPath = Join-Path -Path $env:Temp -ChildPath $WinScpstrExportFileName\\n\\n # Export the registry key\\n & reg.exe export $WinScpExportRegKey $WinScpExportPath\\n\\n # Copy the exported file to the backup destination\\n Copy-Item -Path $WinScpExportPath -Destination $BackupPath\\n\\n # Clean up the temporary exported file\\n Remove-Item -Path $WinScpExportPath\\n}\\n\\nExport-WinSCPSettings\\n \\n\\nAnd just like that, you've backed up your WinSCP settings! It's one of those things we always say we'll do but never get around to. Well, today was the day for me."}]
